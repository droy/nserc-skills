---
name: nserc-discovery-grant
description: This skill should be used when writing or reviewing NSERC Discovery Grant applications - provides Merit Indicator framework, cross-disciplinary writing guidance, and systematic coverage checks for the three evaluation criteria (Excellence of Researcher, Merit of Proposal, HQP Training)
---

# NSERC Discovery Grant Writing

## Overview

This skill guides the preparation of NSERC Discovery Grant applications by grounding all advice in **Merit Indicators** - the specific items that reviewers evaluate using a 6-level scale (Exceptional, Outstanding, Very Strong, Strong, Moderate, Insufficient).

**When to use this skill**:
- Drafting any section of a Discovery Grant application
- Reviewing application drafts for completeness
- Planning application strategy and timeline
- Addressing reviewer feedback from previous submissions

**Key principles**:
- **Package coherence**: NSERC applications are evaluated as an integrated package. All components (research proposal, CCV, HQP training plan, budget justification) must tell a coherent story that addresses the three evaluation criteria.
- **Narrative prose**: Application.md text sections should be written in flowing paragraphs, not bullet points or heavily formatted Markdown. Reviewers read continuous prose, not slide decks.

---

## NSERC Evaluation Framework

### Three Evaluation Criteria

**Official Merit Indicators document**: https://www.nserc-crsng.gc.ca/_doc/Professors-Professeurs/DG_Merit_Indicators_eng.pdf

NSERC reviewers evaluate applications based on three criteria, each assessed independently:

1. **Excellence of the Researcher**
   - Contributions to research
   - Contributions to training of HQP
   - Contributions to other activities (knowledge mobilization, EDI, etc.)

2. **Merit of the Proposal**
   - Originality and significance of research
   - Feasibility and appropriateness of approach
   - Clarity and quality of proposal presentation

3. **Training of Highly Qualified Personnel (HQP)**
   - Quality and impact of proposed HQP training
   - Appropriateness of training environment and opportunities

### The 6-Level Rating Scale

Each Merit Indicator item is rated on this scale:
- **Exceptional** - Among the very best (top ~5%)
- **Outstanding** - Excellent, well above average
- **Very Strong** - Above average, clearly good
- **Strong** - Meets expectations, solid work
- **Moderate** - Below expectations, concerns exist
- **Insufficient** - Does not meet requirements

**Critical insight**: Reviewers don't compare your application to an ideal - they compare it to other applications in the competition. Your job is to make it easy for reviewers to place you in the top categories.

---

## Top 10 Tips (Integrated)

These tips come from experienced NSERC reviewers and should guide every aspect of your application:

**#1: Review grants from senior successful colleagues**
- Ask senior faculty in your department if you can read their successful applications
- Observe how they structure proposals, describe significance, present timelines

**#2: Write it as a package, not separate parts**
- Ensure research proposal connects to past contributions (CCV)
- Verify HQP training plan aligns with proposed research activities
- Check that budget justification matches proposed work
- Tell one coherent story across all components

**#3: Don't sweat the budget if you're new**
- For early-career applicants, modest budgets are fine
- Reviewers care more about research excellence than budget size
- Justify what you request clearly, but don't inflate

**#4: Don't be too ambitious**
- Better to propose focused, feasible work than overreach
- Reviewers value realistic timelines over ambitious scope
- Show you understand potential challenges

**#5: Writing style counts (but don't obsess)**
- Clear, accessible writing > formal academic prose
- Short sentences, active voice, logical flow
- One typo won't kill your application, but sloppy writing signals carelessness

**#6: Write for a GENERAL audience**
- **THIS IS CRITICAL**: Your committee includes reviewers outside your subfield
- Avoid jargon; explain technical concepts in accessible terms
- Start with motivation before technical details
- A non-specialist should understand why your work matters
- **Note**: This applies to ALL applicants - early career, mid-career, and senior researchers alike. Even the most accomplished researchers must make their NSERC proposals accessible to cross-disciplinary committees.

**#7: Ensure you've read the most competitive applications you can get your hands on**
- See Tip #1 - reading successful grants is the best teacher
- Notice how top applicants frame significance, feasibility, training

**#8: Ensure you're addressing the Merit Indicators for each section**
- This is non-negotiable: systematically address every relevant Merit Indicator
- Use the Merit Indicator coverage checklist from the reference files
- Don't assume reviewers will infer - make connections explicit

**#9: Address ALL items in the Merit Indicators, even when not filling a major paragraph**
- Brief mentions count - you don't need full paragraphs for every item
- But complete absence of an item signals a gap
- Coverage > depth for less central items

**#10: CAREFULLY read the instructions in the online application**
- Official instructions: https://www.nserc-crsng.gc.ca/ResearchPortal-PortailDeRecherche/Instructions-Instructions/DG-SD_eng.asp
- Page limits, formatting requirements, required sections
- What goes in CCV vs application form
- Deadline dates and submission process
- Instructions change - verify you have current version

---

## When to Load Reference Files

This skill includes detailed reference files to support specific review tasks. Load these as needed to keep context efficient:

**`references/merit-indicators-checklist.md`**
- Load when: Conducting systematic Merit Indicator coverage checks, creating synthetic reviews, or user explicitly requests comprehensive checklist
- Contains: Complete checklist for Excellence of Researcher, Merit of Proposal, Training of HQP, and Cross-Component Checks
- Use for: Ensuring no Merit Indicator items are overlooked

**`references/application-components.md`**
- Load when: Writing or reviewing specific application components (research proposal, CCV, HQP training plan, budget justification)
- Contains: Detailed requirements, structure, and Merit Indicators for each component
- Use for: Component-specific guidance on what to include and how to structure

**`references/writing-guidance.md`**
- Load when: Drafting prose, reviewing writing style, addressing cross-disciplinary accessibility issues, or planning application timeline
- Contains: Cross-disciplinary writing techniques, common pitfalls with fixes, strategic considerations, application timeline
- Use for: Improving accessibility, avoiding common mistakes, strategic planning

**`references/repository-workflow.md`**
- Load when: Working within an organized NSERC repository with Application.md and LaTeX files, or when user mentions file structure, templates, git workflow
- Contains: Repository structure, reference materials organization, Application.md writing style requirements, LaTeX template system, build commands, synthetic review structure, git workflow
- Use for: Technical repository operations, file management, LaTeX compilation

---

## Review Workflow: Using This Skill

### When Reviewing a Draft Section

**Step 1: Identify which evaluation criterion this section addresses**
- Research proposal → Merit of the Proposal
- CCV → Excellence of the Researcher
- HQP training plan → Training of HQP

**Step 2: Map content to specific Merit Indicator items**
- Load `references/merit-indicators-checklist.md` for systematic coverage check
- List the items from that criterion
- Check which are addressed in the draft
- Identify gaps

**Step 3: Assess from reviewer perspective**
- Put on "reviewer's hat": Cross-disciplinary committee member
- Ask: "If I'm outside this subfield, can I understand the significance?"
- Ask: "Where would I rate this on the 6-level scale?"

**Step 4: Check cross-component consistency** (Tip #2)
- Does research proposal align with CCV expertise?
- Does HQP training plan connect to research objectives?
- Does budget justification match proposed activities?

**Step 5: Apply Top 10 Tips**
- Tip #6 especially: Is this accessible to general audience?
- Tip #8: Are ALL relevant Merit Indicators addressed?
- Tip #9: Even brief mentions for less central items?

**Step 6: Provide structured feedback**
- Reference specific Merit Indicator items
- Explain what reviewers will be looking for
- Suggest concrete improvements
- Note gaps in coverage

### When Providing Feedback

**Always**:
- ✅ Reference Merit Indicators by name
- ✅ Explain reviewer perspective
- ✅ Use 6-level scale language ("For Outstanding rating, you'd need...")
- ✅ Check cross-component consistency
- ✅ Cite relevant Top 10 Tips by number
- ✅ Emphasize writing for general audience (Tip #6)
- ✅ For Application.md content: Write in flowing paragraphs, NOT bullet points or excessive Markdown
- ✅ Load appropriate reference files as needed for the specific task

**Never**:
- ❌ Provide generic grant advice without NSERC-specific grounding
- ❌ Review sections in isolation without checking package coherence
- ❌ Forget that committee is cross-disciplinary
- ❌ Skip the Merit Indicator mapping
- ❌ Assume user knows which items they need to address
- ❌ Write Application.md sections as bullet lists or heavily formatted Markdown

### Note on Deadline Pressure

When user has tight deadline, the structured workflow becomes MORE important, not less. Use it to prioritize: identify the most critical Merit Indicator gaps (load the checklist) and have user address those first. Quick, unfocused feedback wastes precious time.

### Synthetic Reviews

For comprehensive application assessment, create a synthetic review document:
- Organized by three evaluation criteria and Merit Indicator items
- Written from cross-disciplinary reviewer perspective
- Assesses each section on 6-level scale
- Identifies strengths, gaps, and prioritized improvements
- Includes cross-component consistency check
- Load `references/repository-workflow.md` for detailed synthetic review structure

**When to offer**: User requests comprehensive review, application is substantially complete, or preparing for submission.

---

## Resources and References

### Key NSERC Documents

- **Merit Indicators document** - The official evaluation framework
  - PDF: https://www.nserc-crsng.gc.ca/_doc/Professors-Professeurs/DG_Merit_Indicators_eng.pdf
  - Defines the three evaluation criteria and specific items reviewers assess
  - Shows the 6-level rating scale and what each level means

- **Application instructions** - Official requirements and procedures
  - Web page: https://www.nserc-crsng.gc.ca/ResearchPortal-PortailDeRecherche/Instructions-Instructions/DG-SD_eng.asp
  - Comprehensive instructions for completing Discovery Grants application
  - Page limits, formatting requirements, required sections

### Recommended Actions
- Read successful grants from senior colleagues in your department (Tip #1, #7)
- Attend grant-writing workshops at your institution
- Find a writing partner for mutual feedback
- Test drafts with non-specialist readers

---

## Summary: How to Use This Skill

1. **Ground everything in Merit Indicators**: Always reference specific items, use 6-level scale language

2. **Think like a reviewer**: Cross-disciplinary committee member, evaluating against other applications

3. **Write as a package**: Ensure all components tell coherent story (Tip #2)

4. **Write for general audience**: This is non-negotiable (Tip #6)

5. **Use the reference files**: Load checklist for coverage checks, writing guidance for prose reviews, component details for specific sections, repository workflow for technical operations

6. **Apply Top 10 Tips**: Especially #1, #2, #6, #8, #9, #10

7. **Get feedback early**: From colleagues, non-specialists, experienced applicants

The difference between a successful and unsuccessful NSERC application often comes down to making it easy for reviewers to see your excellence. This skill helps you do that systematically.
